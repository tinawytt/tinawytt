{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35e3d95-97e9-49a7-8d38-923901e81d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91/647576444.py:51: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  test_samples = random.sample(sample_set, testset_size)  # IMO the Testset should be static for all splits\n",
      "/tmp/ipykernel_91/647576444.py:54: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  train_samples = random.sample(sample_set - set(test_samples), trainset_size)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "def subfiles(folder,res, join=True, prefix=None, suffix=None, sort=True):\n",
    "    # if join:\n",
    "    #     l = os.path.join\n",
    "    # else:\n",
    "    #     l = lambda x, y: y\n",
    "    # for i in os.listdir(folder):\n",
    "    #     print(i)\n",
    "    # res = [l(folder, i) for i in os.listdir(folder) if os.path.isfile(os.path.join(folder, i))\n",
    "    #         and (prefix is None or i.startswith(prefix))\n",
    "    #         and (suffix is None or i.endswith(suffix))]\n",
    "    \n",
    "    dirList=[]\n",
    "    for i in os.listdir(folder):\n",
    "        wholepath = os.path.join(folder, i)\n",
    "        if os.path.isdir(wholepath):\n",
    "            dirList.append(wholepath)\n",
    "        if os.path.isfile(wholepath):\n",
    "            res.append(wholepath)\n",
    "            if not wholepath.endswith(suffix):\n",
    "                res.remove(wholepath)\n",
    "    if dirList:\n",
    "        for subDir in dirList:\n",
    "            subfiles(subDir,res,join=False,suffix=\"_preprocessed.npz\")\n",
    "    if sort:\n",
    "        res.sort()\n",
    "\n",
    "\n",
    "\n",
    "def create_splits(image_dir='/home/jovyan/main/BraTS2020_TrainingData/'):\n",
    "    \"\"\"File to split the dataset into multiple folds and the train, validation and test set.\n",
    "    :param image_dir: Directory where the images lie in.\n",
    "    \"\"\"\n",
    "    npz_files = []\n",
    "    subfiles(image_dir,npz_files, suffix=\"_preprocessed.npz\", join=False)# npy->npz\n",
    "    sample_size = len(npz_files)\n",
    "\n",
    "    testset_size = int(sample_size * 0.2)#0.25->0.2\n",
    "    valset_size = int(sample_size * 0.2)\n",
    "    trainset_size = sample_size - valset_size - testset_size  # Assure all samples are used.\n",
    "\n",
    "    if sample_size < (trainset_size + valset_size + testset_size):\n",
    "        raise ValueError(\"Assure more total samples exist than train test and val samples combined!\")\n",
    "\n",
    "    splits = []\n",
    "    sample_set = {sample[:-4] for sample in npz_files.copy()}  # Remove the file extension\n",
    "    test_samples = random.sample(sample_set, testset_size)  # IMO the Testset should be static for all splits\n",
    "\n",
    "    for split in range(0, 5):\n",
    "        train_samples = random.sample(sample_set - set(test_samples), trainset_size)\n",
    "        val_samples = list(sample_set - set(train_samples) - set(test_samples))\n",
    "\n",
    "        train_samples.sort()\n",
    "        val_samples.sort()\n",
    "\n",
    "        split_dict = dict()\n",
    "        split_dict['train'] = train_samples\n",
    "        split_dict['val'] = val_samples\n",
    "        split_dict['test'] = test_samples\n",
    "\n",
    "        splits.append(split_dict)\n",
    "\n",
    "    # Todo: IMO it is better to write that dict as JSON. This (unlike pickle) allows the user to inspect the file with an editor\n",
    "    with open(os.path.join(image_dir, 'splits.pkl'), 'wb') as f:\n",
    "        pickle.dump(splits, f)\n",
    "\n",
    "    splits_sanity_check(image_dir)\n",
    "\n",
    "\n",
    "# ToDo: The naming \"splits.pkl should not be distributed over multiple files. This makes changing of it less clear.\n",
    "#   Instead move saving and loading to one file. (Here would be a good place)\n",
    "#   Other usages are: spleen/create_splits.py:57 (Which is redundand anyways?);\n",
    "#   UNetExperiment3D.py:55  and UNetExperiment.py:55\n",
    "def splits_sanity_check(path):\n",
    "    \"\"\" Takes path to a splits file and verifies that no samples from the test dataset leaked into train or validation.\n",
    "    :param path\n",
    "    \"\"\"\n",
    "    with open(os.path.join(path, 'splits.pkl'), 'rb') as f:\n",
    "        splits = pickle.load(f)\n",
    "        for i in range(len(splits)):\n",
    "            samples = splits[i]\n",
    "            tr_samples = set(samples[\"train\"])\n",
    "            vl_samples = set(samples[\"val\"])\n",
    "            ts_samples = set(samples[\"test\"])\n",
    "\n",
    "            assert len(tr_samples.intersection(vl_samples)) == 0, \"Train and validation samples overlap!\"\n",
    "            assert len(vl_samples.intersection(ts_samples)) == 0, \"Validation and Test samples overlap!\"\n",
    "            assert len(tr_samples.intersection(ts_samples)) == 0, \"Train and Test samples overlap!\"\n",
    "    return\n",
    "\n",
    "create_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb811b-26ee-4f4a-9b29-22a596bc4ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
