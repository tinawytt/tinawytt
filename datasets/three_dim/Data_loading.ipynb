{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "av9RCfswtnhN",
    "outputId": "d350c391-7977-4cc5-d1d0-b9a5e5a6235a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn==0.4.2 in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.4.2) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.4.2) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.4.2) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip3 uninstall scikit-learn\n",
    "# !pip3 install scikit-learn==0.24.2\n",
    "# !pip3 uninstall imbalanced-learn==0.5.0\n",
    "!pip3 install imbalanced-learn==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydCZ2vYmsmfO",
    "outputId": "781d0afc-3254-4a90-a749-79a4c4d6df31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trixi in /usr/local/lib/python3.7/dist-packages (0.1.2.2)\n",
      "Requirement already satisfied: imageio>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from trixi) (2.16.0)\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from trixi) (1.10.0+cu111)\n",
      "Requirement already satisfied: scikit-learn==0.20.2 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.20.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (1.4.1)\n",
      "Requirement already satisfied: python-telegram-bot>=10.1.0 in /usr/local/lib/python3.7/dist-packages (from trixi) (13.11)\n",
      "Requirement already satisfied: pathos>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.2.8)\n",
      "Requirement already satisfied: portalocker>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from trixi) (1.21.5)\n",
      "Requirement already satisfied: visdom>=0.1.8.4 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.1.8.9)\n",
      "Requirement already satisfied: graphviz>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from trixi) (3.2.2)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.3.0)\n",
      "Requirement already satisfied: plotly>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (5.5.0)\n",
      "Requirement already satisfied: Flask>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from trixi) (1.1.4)\n",
      "Requirement already satisfied: Pillow>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from trixi) (9.0.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.11.1+cu111)\n",
      "Requirement already satisfied: slackclient>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (2.9.3)\n",
      "Requirement already satisfied: seaborn>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.11.2)\n",
      "Requirement already satisfied: tb-nightly==1.14.0a20190523 in /usr/local/lib/python3.7/dist-packages (from trixi) (1.14.0a20190523)\n",
      "Requirement already satisfied: umap-learn>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from trixi) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (1.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (3.3.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190523->trixi) (1.0.1)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.12.2->trixi) (7.1.2)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.12.2->trixi) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.12.2->trixi) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.12.2->trixi) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly==1.14.0a20190523->trixi) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==1.14.0a20190523->trixi) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==1.14.0a20190523->trixi) (3.10.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->trixi) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->trixi) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->trixi) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->trixi) (1.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.0->trixi) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.0->trixi) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.0->trixi) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.0->trixi) (1.6.6.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=2.5.1->trixi) (8.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot>=10.1.0->trixi) (6.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot>=10.1.0->trixi) (2021.10.8)\n",
      "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot>=10.1.0->trixi) (3.6.3)\n",
      "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot>=10.1.0->trixi) (4.2.2)\n",
      "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot>=10.1.0->trixi) (2018.9)\n",
      "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot>=10.1.0->trixi) (57.4.0)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot>=10.1.0->trixi) (1.5.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn>=0.8.1->trixi) (1.3.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>3.5.2 in /usr/local/lib/python3.7/dist-packages (from slackclient>=1.3.1->trixi) (3.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (2.0.11)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (1.7.2)\n",
      "Requirement already satisfied: numba!=0.47,>=0.46 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.3.6->trixi) (0.51.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba!=0.47,>=0.46->umap-learn>=0.3.6->trixi) (0.34.0)\n",
      "Requirement already satisfied: torchfile in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.4->trixi) (0.1.0)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.4->trixi) (1.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.4->trixi) (2.23.0)\n",
      "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.4->trixi) (1.32)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.4->trixi) (22.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>3.5.2->slackclient>=1.3.1->trixi) (2.10)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.7/dist-packages (from jsonpatch->visdom>=0.1.8.4->trixi) (2.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.4->trixi) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.4->trixi) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install trixi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2S22Nyy9-Ll"
   },
   "outputs": [],
   "source": [
    "from trixi.util.pytorchutils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pHXu2WlBqJ3i",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9f4bc06c-09a8-447e-907b-1d681d1393e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from trixi.util.pytorchutils import set_seed\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(base_dir, pattern='*.npz', keys=None):\n",
    "    fls = []\n",
    "    files_len = []\n",
    "    dataset = []\n",
    "\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        i = 0\n",
    "        for filename in sorted(fnmatch.filter(files, pattern)):\n",
    "\n",
    "            if keys is not None and filename[:-4] in keys:\n",
    "                npz_file = os.path.join(root, filename)\n",
    "                numpy_array = np.load(npz_file)['data']\n",
    "\n",
    "                fls.append(npz_file)\n",
    "                files_len.append(numpy_array.shape[1])\n",
    "\n",
    "                dataset.extend([i])\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    return fls, files_len, dataset\n",
    "\n",
    "class SlimDataLoaderBase(object):\n",
    "    def __init__(self, data, batch_size, number_of_threads_in_multithreaded=None):\n",
    "        __metaclass__ = ABCMeta\n",
    "        self.number_of_threads_in_multithreaded = number_of_threads_in_multithreaded\n",
    "        self._data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.thread_id = 0\n",
    "\n",
    "    def set_thread_id(self, thread_id):\n",
    "        self.thread_id = thread_id\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.generate_train_batch()\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_train_batch(self):\n",
    "        '''override this\n",
    "        Generate your batch from self._data .Make sure you generate the correct batch size (self.BATCH_SIZE)\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "\n",
    "class NumpyDataLoader(SlimDataLoaderBase):\n",
    "    def __init__(self, base_dir, mode=\"train\", batch_size=16, num_batches=10000000,\n",
    "                 seed=None, file_pattern='*.npz', label=1, input=(0,), keys=None):\n",
    "\n",
    "        self.files, self.file_len, self.dataset = load_dataset(base_dir=base_dir, pattern=file_pattern, keys=keys )\n",
    "        super(NumpyDataLoader, self).__init__(self.dataset, batch_size, num_batches)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.use_next = False\n",
    "        if mode == \"train\":\n",
    "            self.use_next = False\n",
    "\n",
    "        self.idxs = list(range(0, len(self.dataset)))\n",
    "\n",
    "        self.data_len = len(self.dataset)\n",
    "\n",
    "        self.num_batches = min((self.data_len // self.batch_size)+10, num_batches)\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = (label,)\n",
    "        self.input = input\n",
    "        self.label = label\n",
    "\n",
    "        self.np_data = np.asarray(self.dataset)\n",
    "\n",
    "    def reshuffle(self):\n",
    "        print(\"Reshuffle...\")\n",
    "        random.shuffle(self.idxs)\n",
    "        print(\"Initializing... this might take a while...\")\n",
    "\n",
    "    def generate_train_batch(self):\n",
    "        open_arr = random.sample(self._data, self.batch_size)\n",
    "        return self.get_data_from_array(open_arr)\n",
    "\n",
    "    def __len__(self):\n",
    "        n_items = min(self.data_len // self.batch_size, self.num_batches)\n",
    "        return n_items\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        idxs = self.idxs\n",
    "        data_len = len(self.dataset)\n",
    "        np_data = self.np_data\n",
    "\n",
    "        if item > len(self):\n",
    "            raise StopIteration()\n",
    "        if (item * self.batch_size) == data_len:\n",
    "            raise StopIteration()\n",
    "\n",
    "        start_idx = (item * self.batch_size) % data_len\n",
    "        stop_idx = ((item + 1) * self.batch_size) % data_len\n",
    "\n",
    "        if ((item + 1) * self.batch_size) == data_len:\n",
    "            stop_idx = data_len\n",
    "\n",
    "        if stop_idx > start_idx:\n",
    "            idxs = idxs[start_idx:stop_idx]\n",
    "        else:\n",
    "            raise StopIteration()\n",
    "\n",
    "        open_arr = np_data[idxs]\n",
    "\n",
    "        return self.get_data_from_array(open_arr)\n",
    "\n",
    "    def get_data_from_array(self, open_array):\n",
    "        data = []\n",
    "        fnames = []\n",
    "        idxs = []\n",
    "        labels = []\n",
    "\n",
    "        for idx in open_array:\n",
    "            fn_name = self.files[idx]\n",
    "\n",
    "            numpy_array = np.load(fn_name)\n",
    "\n",
    "            data.append(numpy_array[list(self.input)])   # 'None' keeps the dimension\n",
    "\n",
    "            if self.label is not None:\n",
    "                labels.append(numpy_array[list(self.input)])   # 'None' keeps the dimension\n",
    "\n",
    "            fnames.append(self.files[idx])\n",
    "            idxs.append(idx)\n",
    "\n",
    "        ret_dict = {'data': data, 'fnames': fnames, 'idxs': idxs}\n",
    "        if self.label is not None:\n",
    "            ret_dict['seg'] = labels\n",
    "\n",
    "        return ret_dict\n",
    "\n",
    "class WrappedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.is_indexable = False\n",
    "        if hasattr(self.dataset, \"__getitem__\") and not (hasattr(self.dataset, \"use_next\") and self.dataset.use_next is True):\n",
    "            self.is_indexable = True\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if not self.is_indexable:\n",
    "            item = next(self.dataset)\n",
    "        else:\n",
    "            item = self.dataset[index]\n",
    "        # item = self.transform(**item)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.dataset.num_batches)\n",
    "\n",
    "\n",
    "class MultiThreadedDataLoader(object):\n",
    "    def __init__(self, data_loader,  num_processes,transform=None, **kwargs):\n",
    "\n",
    "        self.cntr = 1\n",
    "        self.ds_wrapper = WrappedDataset(data_loader, transform)\n",
    "\n",
    "        self.generator = DataLoader(self.ds_wrapper, batch_size=1, shuffle=False, sampler=None, batch_sampler=None,\n",
    "                                    num_workers=num_processes, pin_memory=True, drop_last=False,\n",
    "                                    worker_init_fn=self.get_worker_init_fn())\n",
    "\n",
    "        self.num_processes = num_processes\n",
    "        self.iter = None\n",
    "\n",
    "    def get_worker_init_fn(self):\n",
    "        def init_fn(worker_id):\n",
    "            set_seed(worker_id + self.cntr)\n",
    "\n",
    "        return init_fn\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.kill_iterator()\n",
    "        self.iter = iter(self.generator)\n",
    "        return self.iter\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iter is None:\n",
    "            self.iter = iter(self.generator)\n",
    "        return next(self.iter)\n",
    "\n",
    "    def renew(self):\n",
    "        self.cntr += 1\n",
    "        self.kill_iterator()\n",
    "        self.generator.worker_init_fn = self.get_worker_init_fn()\n",
    "        self.iter = iter(self.generator)\n",
    "\n",
    "    def kill_iterator(self):\n",
    "        try:\n",
    "            if self.iter is not None:\n",
    "                self.iter._shutdown_workers()\n",
    "                for p in self.iter.workers:\n",
    "                    p.terminate()\n",
    "        except:\n",
    "            print(\"Could not kill Dataloader Iterator\")\n",
    "\n",
    "class NumpyDataSet(object):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir, mode=\"train\", batch_size=16, num_batches=10000000, seed=None, num_processes=8, num_cached_per_queue=8 * 4, target_size=128,\n",
    "                 file_pattern='*.npz', label=1, input=(0,), do_reshuffle=True, keys=None):#8*4->2*4  8->2\n",
    "\n",
    "        data_loader = NumpyDataLoader(base_dir=base_dir, mode=mode, batch_size=batch_size, num_batches=num_batches, seed=seed, file_pattern=file_pattern,\n",
    "                                      input=input, label=label, keys=keys)\n",
    "\n",
    "        self.data_loader = data_loader\n",
    "        self.batch_size = batch_size\n",
    "        self.do_reshuffle = do_reshuffle\n",
    "        self.number_of_slices = 1\n",
    "\n",
    "        self.transforms = None\n",
    "        self.augmenter = MultiThreadedDataLoader(data_loader, num_processes,num_cached_per_queue=num_cached_per_queue, seeds=seed,\n",
    "                                                 shuffle=do_reshuffle)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.do_reshuffle:\n",
    "            self.data_loader.reshuffle()\n",
    "        self.augmenter.renew()\n",
    "        return self.augmenter\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self.augmenter)\n",
    "\n",
    "data_dir='/home/jovyan/main/BraTS2020_TrainingData/'\n",
    "with open(os.path.join(data_dir, \"splits.pkl\"), 'rb') as f:\n",
    "  splits = pickle.load(f)\n",
    "tr_keys = splits[0]['train']\n",
    "val_keys = splits[0]['val']\n",
    "test_keys = splits[0]['test']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data_loader = NumpyDataSet(data_dir, target_size=64, batch_size=8,keys=tr_keys)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data_loading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
